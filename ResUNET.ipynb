{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOgZdlERsl2O",
        "outputId": "2d0b5437-dbb0-447e-877d-571a8ee4f63b"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/lorenzoorsingher/resunet.git\n",
        "!pip install lpips\n",
        "!pip install python-dotenv\n",
        "%cd resunet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YbgSfKEJl5S3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "from copy import copy\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import SGD\n",
        "\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "\n",
        "import lpips\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "COLAB = False\n",
        "\n",
        "if COLAB:\n",
        "    from google.colab.patches import cv2_imshow\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    cv.imshow = lambda n,i : cv2_imshow(i)\n",
        "\n",
        "    zip_path = \"/content/drive/MyDrive/tesi/data/lfw/data/images.zip\"\n",
        "    jsonpath = \"data/\"\n",
        "    datasetpath = \"data/\"\n",
        "    colorpath = datasetpath + \"color/\"\n",
        "    bwpath = datasetpath + \"bw/\"\n",
        "    savepath = \"data/checkpoints/\"\n",
        "else:\n",
        "    load_dotenv()\n",
        "    # Xmple_path = os.getenv('XMPLE_PATH')\n",
        "    # ymple_path = os.getenv('YMPLE_PATH')\n",
        "    jsonpath = os.getenv('JSON_PATH')\n",
        "    datasetpath = os.getenv('DATA_PATH')\n",
        "    colorpath = datasetpath + \"color/\"\n",
        "    bwpath = datasetpath + \"bw/\"\n",
        "    savepath = os.getenv('SAVE_PATH')\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Py4auicUlhQI"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUFJ5Ro2mJu2",
        "outputId": "1a73f546-cad5-491a-f52d-a38843366635"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzqJjKHWqBtx",
        "outputId": "4c14ca4e-4c71-4590-cac1-157a685d2f1f"
      },
      "outputs": [],
      "source": [
        "from normalize import DataNormalizer\n",
        "\n",
        "dn = DataNormalizer(colorpath, bwpath, jsonpath)\n",
        "dn.get_json()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "p3D_Ucrj75Nj"
      },
      "outputs": [],
      "source": [
        "#@title CustomDataset\n",
        "\n",
        "from dataLoader import CustomDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "mWM7f_ELl_74"
      },
      "outputs": [],
      "source": [
        "#@title ResUNET\n",
        "\n",
        "from model_files.resunet import ResNetUNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jqpDPQYZfF8j",
        "outputId": "9559d13d-34d6-46f4-d339-0e1f28279976"
      },
      "outputs": [],
      "source": [
        "#@title Training Loop\n",
        "\n",
        "LOAD_CHKP = False\n",
        "VIS_DEBUG = True\n",
        "SAVE_PATH = savepath\n",
        "BATCH = 32\n",
        "EPOCH = 300\n",
        "VISUAL = 1\n",
        "LR = 1e-3\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"[INFO] training using {}...\".format(DEVICE))\n",
        "\n",
        "\n",
        "#folders for checkpoints and degub images\n",
        "if not os.path.exists(SAVE_PATH):\n",
        "  os.mkdir(SAVE_PATH)\n",
        "current_savepath = SAVE_PATH + \"run_\"+str(round(time.time()))+\"/\"\n",
        "img_savepath = current_savepath + \"imgs/\"\n",
        "os.mkdir(current_savepath)\n",
        "os.mkdir(img_savepath)\n",
        "\n",
        "\n",
        "#load the model\n",
        "#ae = model.SimplerAE2().to(DEVICE)\n",
        "model = ResNetUNet().to(DEVICE)\n",
        "\n",
        "insize, outsize = ((32,32),(32,32))\n",
        "#load the custom dattaset and correspondent dataloader\n",
        "dataset = CustomDataset(insize, outsize, datasetpath, jsonpath)\n",
        "data_loader = DataLoader(dataset, batch_size=BATCH, shuffle=True)\n",
        "\n",
        "#print model and parameters number\n",
        "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "params = sum([np.prod(p.size()) for p in model_parameters])\n",
        "print(params, \" total params\")\n",
        "print(model)\n",
        "\n",
        "#setup optimizer and loss function\n",
        "opt = SGD(model.parameters(), lr=LR)\n",
        "lpips_loss = lpips.LPIPS(net='alex')\n",
        "if DEVICE == \"cuda\":\n",
        "  lpips_loss.cuda()\n",
        "lossFunc = lpips_loss\n",
        "\n",
        "\n",
        "\n",
        "#if set, load the a saved checkpoint\n",
        "if (LOAD_CHKP):\n",
        "    chkp_path = \"checkpoints/run_1688680178/checkpoint_8.chkp\"\n",
        "    checkpoint = torch.load(chkp_path)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    opt.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    epoch = checkpoint['epoch']\n",
        "\n",
        "# ### load example image (not from dataset)\n",
        "# Xmple = cv.imread(Xmple_path)\n",
        "# ymple = cv.imread(ymple_path)\n",
        "# Xmple = cv.cvtColor(Xmple, cv.COLOR_BGR2GRAY)\n",
        "\n",
        "# Xmple = cv.resize(Xmple, dataset.insize)\n",
        "# ymple = cv.resize(ymple, dataset.outsize)\n",
        "\n",
        "# Xmple, ymple = dataset.normalize(Xmple, ymple)\n",
        "\n",
        "# Xmple = torch.tensor([[Xmple]])\n",
        "# ymple = torch.tensor([ymple])\n",
        "\n",
        "# Xmple = Xmple.permute(0,1, 3, 2)\n",
        "# ymple = ymple.permute(0,3, 2, 1)\n",
        "# Xmple = Xmple.float()\n",
        "# ymple = ymple.float()\n",
        "# ########################################\n",
        "\n",
        "#cv.namedWindow(\"encode_decode_result\", cv.WINDOW_NORMAL)\n",
        "\n",
        "#training loop\n",
        "model.train()\n",
        "epoch = 0\n",
        "for i in range(EPOCH):\n",
        "    print(\"############################### EPOCH \",i,\"#####################################################################\\n\")\n",
        "\n",
        "    epoch_start = time.time()\n",
        "    epochLoss = 0\n",
        "    batchItems = 0\n",
        "    stop = True\n",
        "    count = 0\n",
        "\n",
        "    #loop thru single batch\n",
        "    for batch_id, (X,y) in enumerate(data_loader):\n",
        "\n",
        "        #convert tensors to float and load em to device\n",
        "        X = X.float()\n",
        "        y = y.float()\n",
        "        (X,y) = (X.to(DEVICE), y.to(DEVICE))\n",
        "\n",
        "        #actual trainign lol #####\n",
        "        predictions = model(X)\n",
        "\n",
        "        loss = lossFunc(predictions, y)\n",
        "\n",
        "        opt.zero_grad()\n",
        "        #breakpoint()\n",
        "        loss.sum().backward()\n",
        "        opt.step()\n",
        "        ##########################\n",
        "\n",
        "        count+=1\n",
        "        if count%VISUAL==0 and VIS_DEBUG:\n",
        "\n",
        "            #basically multiply std and add mean for each channel\n",
        "            Ximg, _ = dataset.denormalize(copy(X[0].detach().transpose(0,2).cpu().numpy()),None)\n",
        "            pred, yimg = dataset.denormalize(copy(predictions[0].detach().transpose(0,2).cpu().numpy()),copy(y[0].detach().transpose(0,2).cpu().numpy()))\n",
        "\n",
        "            #tensor to ndarray, resize and gray to bgr to allaw hstacking\n",
        "            Ximg = Ximg.astype(np.uint8)\n",
        "            Ximg = cv.resize(Ximg, yimg.shape[:2])\n",
        "            Ximg = cv.cvtColor(Ximg,cv.COLOR_GRAY2BGR)\n",
        "            yimg = yimg.astype(np.uint8)\n",
        "            #some values exceed 254 or are negative (no tanh, sigmoid or similar in net\n",
        "            #because data is already standardized)\n",
        "            pred[pred > 254] = 254\n",
        "            pred[pred < 0] = 0\n",
        "            pred = pred.astype(np.uint8)\n",
        "\n",
        "            cv.imshow(\"im\",np.hstack([Ximg,yimg,pred]))\n",
        "            #cv.imwrite(img_savepath+\"img_\"+str(i)+\"_\"+str(count)+\".jpg\",np.hstack([ex_Ximg,ex_yimg,ex_pred]))\n",
        "            print(\"batch_loss: \", round(loss.sum().item()/BATCH,4))\n",
        "            cv.waitKey(1)\n",
        "\n",
        "        epochLoss += loss.sum().item()\n",
        "        batchItems += BATCH\n",
        "    epoch_end = time.time()\n",
        "    epoch_time = epoch_end - epoch_start\n",
        "    print(\"\\nepoch_time: \",round(epoch_time,2), \" seconds\")\n",
        "    print(\"epoch_loss: \", round(epochLoss/batchItems,8))\n",
        "\n",
        "    #save checkpoint\n",
        "    print(\"[SAVE] saving checkpoint...\")\n",
        "    torch.save({\n",
        "            'epoch': i,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': opt.state_dict(),\n",
        "            'loss': epochLoss/batchItems,\n",
        "            }, current_savepath + \"checkpoint_\"+str(i)+\".chkp\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KrUr8uQPUER4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
