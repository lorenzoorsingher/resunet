{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOgZdlERsl2O",
        "outputId": "2d0b5437-dbb0-447e-877d-571a8ee4f63b"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/lorenzoorsingher/resunet.git\n",
        "!pip install lpips\n",
        "!pip install python-dotenv\n",
        "%cd resunet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "YbgSfKEJl5S3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2 as cv\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "\"\"\"\n",
        "When running this notebook on colab set the COLAB\n",
        "variable to True\n",
        "\"\"\"\n",
        "COLAB = False\n",
        "\n",
        "if COLAB:\n",
        "    from google.colab.patches import cv2_imshow\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    cv.imshow = lambda n,i : cv2_imshow(i)\n",
        "    !unzip {zip_path} -d {datasetpath}\n",
        "    zip_path = \"/content/drive/MyDrive/tesi/data/lfw/data/images.zip\"\n",
        "    jsonpath = \"data/\"\n",
        "    datasetpath = \"data/\"\n",
        "    \n",
        "    colorpath = datasetpath + \"color/\"\n",
        "    bwpath = datasetpath + \"bw/\"\n",
        "    savepath = \"data/checkpoints/\"\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzqJjKHWqBtx",
        "outputId": "4c14ca4e-4c71-4590-cac1-157a685d2f1f"
      },
      "outputs": [],
      "source": [
        "#@title Dataset standardization\n",
        "\n",
        "\"\"\"\n",
        "Run this cell if you don't have the json file with the standardization data\n",
        "for the dataset\n",
        "\"\"\"\n",
        "\n",
        "from normalize import DataNormalizer\n",
        "\n",
        "dn = DataNormalizer(colorpath, bwpath, jsonpath)\n",
        "dn.get_json()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "usage: train.py [-h] [--json JSON] [--data DATA] [--save SAVE]\n",
            "                [--insize INSIZE] [--outsize OUTSIZE] [--batch BATCH]\n",
            "                [--epochs EPOCHS] [--video VIDEO] [--no-video]\n",
            "                [--load-chkp LOADCHKP]\n",
            "\n",
            "options:\n",
            "  -h, --help            show this help message and exit\n",
            "  --json JSON           Path where json file will be saved/read\n",
            "  --data DATA           Path to the dataset\n",
            "  --save SAVE           Path to where checkpoints will be saved\n",
            "  --insize INSIZE       Size of input image\n",
            "  --outsize OUTSIZE     Size of output image\n",
            "  --batch BATCH         Size of batches\n",
            "  --epochs EPOCHS       Number of epochs\n",
            "  --video VIDEO         Number of batches between every visualization\n",
            "  --no-video            Set for no visual debug\n",
            "  --load-chkp LOADCHKP  Path to checkpoints to be loaded\n"
          ]
        }
      ],
      "source": [
        "!python train.py -h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jqpDPQYZfF8j",
        "outputId": "9559d13d-34d6-46f4-d339-0e1f28279976"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] training using cpu...\n",
            "/home/lollo/miniconda3/envs/envresunet/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/home/lollo/miniconda3/envs/envresunet/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "15114158  total params\n",
            "ResNetUNet(\n",
            "  (base_model): ResNet(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "    (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
            "  )\n",
            "  (layer1): Sequential(\n",
            "    (0): UpBlock(\n",
            "      (upsample): Sequential(\n",
            "        (0): Upsample(scale_factor=2.0, mode='bilinear')\n",
            "        (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (conv1): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): UpBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): UpBlock(\n",
            "      (upsample): Sequential(\n",
            "        (0): Upsample(scale_factor=2.0, mode='bilinear')\n",
            "        (1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (conv1): ConvTranspose2d(512, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): UpBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): UpBlock(\n",
            "      (upsample): Sequential(\n",
            "        (0): Upsample(scale_factor=2.0, mode='bilinear')\n",
            "        (1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (conv1): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): UpBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (out): Sequential(\n",
            "    (0): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
            "    (1): ReLU()\n",
            "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): ConvTranspose2d(64, 3, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
            "  )\n",
            "  (convBw): Conv2d(1, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            ")\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "/home/lollo/miniconda3/envs/envresunet/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Loading model from: /home/lollo/miniconda3/envs/envresunet/lib/python3.11/site-packages/lpips/weights/v0.1/alex.pth\n",
            "############################### EPOCH  0 #####################################################################\n",
            "\n",
            "/home/lollo/Documents/nn/resnet_unet_mod/dataLoader.py:89: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343904035/work/torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  Ximg_tensor = torch.tensor([Ximg])\n",
            "batch_loss:  0.1767\n",
            "batch_loss:  0.1275\n",
            "^C\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/lollo/Documents/nn/resnet_unet_mod/train.py\", line 85, in <module>\n",
            "    for batch_id, (X,y) in enumerate(data_loader):\n",
            "  File \"/home/lollo/miniconda3/envs/envresunet/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 633, in __next__\n",
            "    data = self._next_data()\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/lollo/miniconda3/envs/envresunet/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 677, in _next_data\n",
            "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/lollo/miniconda3/envs/envresunet/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/lollo/miniconda3/envs/envresunet/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "            ~~~~~~~~~~~~^^^^^\n",
            "  File \"/home/lollo/Documents/nn/resnet_unet_mod/dataLoader.py\", line 80, in __getitem__\n",
            "    yimg = cv2.imread(color_path)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "if COLAB:\n",
        "    !python train.py --json {jsonpath} --data {datasetpath} -- save{savepath}\n",
        "else:\n",
        "\n",
        "    !python train.py "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KrUr8uQPUER4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
