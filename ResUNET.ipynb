{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YbgSfKEJl5S3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "from copy import copy\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import SGD\n",
        "\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "\n",
        "import lpips\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "COLAB = False\n",
        "\n",
        "if COLAB:\n",
        "    from google.colab.patches import cv2_imshow\n",
        "    \n",
        "    cv.imshow = lambda n,i : cv2_imshow(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Py4auicUlhQI"
      },
      "outputs": [],
      "source": [
        "load_dotenv()\n",
        "\n",
        "zip_path = os.getenv('ZIP_PATH')\n",
        "Xmple_path = os.getenv('XMPLE_PATH')\n",
        "ymple_path = os.getenv('YMPLE_PATH')\n",
        "jsonpath = os.getenv('JSON_PATH')\n",
        "datasetpath = os.getenv('DATA_PATH')\n",
        "colorpath = datasetpath + \"/color/\"\n",
        "bwpath = datasetpath + \"/bw/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUFJ5Ro2mJu2",
        "outputId": "bad27a3b-9674-448c-8e8c-6dadb73102d1"
      },
      "outputs": [],
      "source": [
        "!unzip {zip_path} -d {datasetpath}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzqJjKHWqBtx",
        "outputId": "1ab11932-2bf4-40ad-b2f2-718fe6291235"
      },
      "outputs": [],
      "source": [
        "from normalize import DataNormalizer\n",
        "\n",
        "dn = DataNormalizer(colorpath, bwpath, jsonpath)\n",
        "dn.get_json()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "id": "p3D_Ucrj75Nj"
      },
      "outputs": [],
      "source": [
        "#@title CustomDataset\n",
        "\n",
        "from dataLoader import CustomDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellView": "form",
        "id": "mWM7f_ELl_74"
      },
      "outputs": [],
      "source": [
        "#@title ResUNET\n",
        "\n",
        "from model_files.resunet import ResNetUNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jqpDPQYZfF8j",
        "outputId": "1f711edb-c9fb-47a4-9d9b-88a14b154def"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] training using cpu...\n",
            "15114158  total params\n",
            "ResNetUNet(\n",
            "  (base_model): ResNet(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "    (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
            "  )\n",
            "  (layer1): Sequential(\n",
            "    (0): UpBlock(\n",
            "      (upsample): Sequential(\n",
            "        (0): Upsample(scale_factor=2.0, mode='bilinear')\n",
            "        (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (conv1): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): UpBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): UpBlock(\n",
            "      (upsample): Sequential(\n",
            "        (0): Upsample(scale_factor=2.0, mode='bilinear')\n",
            "        (1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (conv1): ConvTranspose2d(512, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): UpBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): UpBlock(\n",
            "      (upsample): Sequential(\n",
            "        (0): Upsample(scale_factor=2.0, mode='bilinear')\n",
            "        (1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (conv1): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): UpBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (out): Sequential(\n",
            "    (0): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
            "    (1): ReLU()\n",
            "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): ConvTranspose2d(64, 3, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
            "  )\n",
            "  (convBw): Conv2d(1, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            ")\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /home/lollo/miniconda3/envs/envresunet/lib/python3.11/site-packages/lpips/weights/v0.1/alex.pth\n",
            "############################### EPOCH  0 #####################################################################\n",
            "\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'cv2_imshow' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[6], line 125\u001b[0m\n\u001b[1;32m    122\u001b[0m pred[pred \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    123\u001b[0m pred \u001b[39m=\u001b[39m pred\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39muint8)\n\u001b[0;32m--> 125\u001b[0m cv2_imshow(np\u001b[39m.\u001b[39mhstack([Ximg,yimg,pred]))\n\u001b[1;32m    126\u001b[0m \u001b[39m#cv.imwrite(img_savepath+\"img_\"+str(i)+\"_\"+str(count)+\".jpg\",np.hstack([ex_Ximg,ex_yimg,ex_pred]))\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mbatch_loss: \u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mround\u001b[39m(loss\u001b[39m.\u001b[39msum()\u001b[39m.\u001b[39mitem()\u001b[39m/\u001b[39mBATCH,\u001b[39m4\u001b[39m))\n",
            "\u001b[0;31mNameError\u001b[0m: name 'cv2_imshow' is not defined"
          ]
        }
      ],
      "source": [
        "#@title Training Loop\n",
        "\n",
        "LOAD_CHKP = False\n",
        "VIS_DEBUG = True\n",
        "SAVE_PATH = os.getenv('SAVE_PATH')\n",
        "BATCH = 32\n",
        "EPOCH = 300\n",
        "VISUAL = 1\n",
        "LR = 1e-3\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"[INFO] training using {}...\".format(DEVICE))\n",
        "\n",
        "\n",
        "#folders for checkpoints and degub images\n",
        "if not os.path.exists(SAVE_PATH):\n",
        "  os.mkdir(SAVE_PATH)\n",
        "current_savepath = SAVE_PATH + \"run_\"+str(round(time.time()))+\"/\"\n",
        "img_savepath = current_savepath + \"imgs/\"\n",
        "os.mkdir(current_savepath)\n",
        "os.mkdir(img_savepath)\n",
        "\n",
        "\n",
        "#load the model\n",
        "#ae = model.SimplerAE2().to(DEVICE)\n",
        "model = ResNetUNet().to(DEVICE)\n",
        "\n",
        "insize, outsize = ((32,32),(32,32))\n",
        "#load the custom dattaset and correspondent dataloader\n",
        "dataset = CustomDataset(insize, outsize, datasetpath, jsonpath)\n",
        "data_loader = DataLoader(dataset, batch_size=BATCH, shuffle=True)\n",
        "\n",
        "#print model and parameters number\n",
        "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "params = sum([np.prod(p.size()) for p in model_parameters])\n",
        "print(params, \" total params\")\n",
        "print(model)\n",
        "\n",
        "#setup optimizer and loss function\n",
        "opt = SGD(model.parameters(), lr=LR)\n",
        "lpips_loss = lpips.LPIPS(net='alex')\n",
        "if DEVICE == \"cuda\":\n",
        "  lpips_loss.cuda()\n",
        "lossFunc = lpips_loss\n",
        "\n",
        "\n",
        "\n",
        "#if set, load the a saved checkpoint\n",
        "if (LOAD_CHKP):\n",
        "    chkp_path = \"checkpoints/run_1688680178/checkpoint_8.chkp\"\n",
        "    checkpoint = torch.load(chkp_path)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    opt.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    epoch = checkpoint['epoch']\n",
        "\n",
        "# ### load example image (not from dataset)\n",
        "# Xmple = cv.imread(Xmple_path)\n",
        "# ymple = cv.imread(ymple_path)\n",
        "# Xmple = cv.cvtColor(Xmple, cv.COLOR_BGR2GRAY)\n",
        "\n",
        "# Xmple = cv.resize(Xmple, dataset.insize)\n",
        "# ymple = cv.resize(ymple, dataset.outsize)\n",
        "\n",
        "# Xmple, ymple = dataset.normalize(Xmple, ymple)\n",
        "\n",
        "# Xmple = torch.tensor([[Xmple]])\n",
        "# ymple = torch.tensor([ymple])\n",
        "\n",
        "# Xmple = Xmple.permute(0,1, 3, 2)\n",
        "# ymple = ymple.permute(0,3, 2, 1)\n",
        "# Xmple = Xmple.float()\n",
        "# ymple = ymple.float()\n",
        "# ########################################\n",
        "\n",
        "#cv.namedWindow(\"encode_decode_result\", cv.WINDOW_NORMAL)\n",
        "\n",
        "#training loop\n",
        "model.train()\n",
        "epoch = 0\n",
        "for i in range(EPOCH):\n",
        "    print(\"############################### EPOCH \",i,\"#####################################################################\\n\")\n",
        "\n",
        "    epoch_start = time.time()\n",
        "    epochLoss = 0\n",
        "    batchItems = 0\n",
        "    stop = True\n",
        "    count = 0\n",
        "\n",
        "    #loop thru single batch\n",
        "    for batch_id, (X,y) in enumerate(data_loader):\n",
        "\n",
        "        #convert tensors to float and load em to device\n",
        "        X = X.float()\n",
        "        y = y.float()\n",
        "        (X,y) = (X.to(DEVICE), y.to(DEVICE))\n",
        "\n",
        "        #actual trainign lol #####\n",
        "        predictions = model(X)\n",
        "\n",
        "        loss = lossFunc(predictions, y)\n",
        "\n",
        "        opt.zero_grad()\n",
        "        #breakpoint()\n",
        "        loss.sum().backward()\n",
        "        opt.step()\n",
        "        ##########################\n",
        "\n",
        "        count+=1\n",
        "        if count%VISUAL==0 and VIS_DEBUG:\n",
        "\n",
        "            #basically multiply std and add mean for each channel\n",
        "            Ximg, _ = dataset.denormalize(copy(X[0].detach().transpose(0,2).cpu().numpy()),None)\n",
        "            pred, yimg = dataset.denormalize(copy(predictions[0].detach().transpose(0,2).cpu().numpy()),copy(y[0].detach().transpose(0,2).cpu().numpy()))\n",
        "\n",
        "            #tensor to ndarray, resize and gray to bgr to allaw hstacking\n",
        "            Ximg = Ximg.astype(np.uint8)\n",
        "            Ximg = cv.resize(Ximg, yimg.shape[:2])\n",
        "            Ximg = cv.cvtColor(Ximg,cv.COLOR_GRAY2BGR)\n",
        "            yimg = yimg.astype(np.uint8)\n",
        "            #some values exceed 254 or are negative (no tanh, sigmoid or similar in net\n",
        "            #because data is already standardized)\n",
        "            pred[pred > 254] = 254\n",
        "            pred[pred < 0] = 0\n",
        "            pred = pred.astype(np.uint8)\n",
        "\n",
        "            cv.imshow(\"im\",np.hstack([Ximg,yimg,pred]))\n",
        "            #cv.imwrite(img_savepath+\"img_\"+str(i)+\"_\"+str(count)+\".jpg\",np.hstack([ex_Ximg,ex_yimg,ex_pred]))\n",
        "            print(\"batch_loss: \", round(loss.sum().item()/BATCH,4))\n",
        "            cv.waitKey(1)\n",
        "\n",
        "        epochLoss += loss.sum().item()\n",
        "        batchItems += BATCH\n",
        "    epoch_end = time.time()\n",
        "    epoch_time = epoch_end - epoch_start\n",
        "    print(\"\\nepoch_time: \",round(epoch_time,2), \" seconds\")\n",
        "    print(\"epoch_loss: \", round(epochLoss/batchItems,8))\n",
        "\n",
        "    #save checkpoint\n",
        "    print(\"[SAVE] saving checkpoint...\")\n",
        "    torch.save({\n",
        "            'epoch': i,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': opt.state_dict(),\n",
        "            'loss': epochLoss/batchItems,\n",
        "            }, current_savepath + \"checkpoint_\"+str(i)+\".chkp\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KrUr8uQPUER4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
